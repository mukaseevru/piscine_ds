{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(estimator, X, y, n_splits=10):\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits)\n",
    "    for train, valid in cv.split(X, y):\n",
    "        estimator.fit(X.iloc[train], y.iloc[train])\n",
    "        y_train_pred = estimator.predict(X.iloc[train])\n",
    "        y_valid_pred = estimator.predict(X.iloc[valid])\n",
    "        train_scores.append(accuracy_score(y.iloc[train], y_train_pred))\n",
    "        valid_scores.append(accuracy_score(y.iloc[valid], y_valid_pred))\n",
    "    for train, valid in zip(train_scores, valid_scores):\n",
    "        print(f'train -  {train:.5f}   {\"|\"}   valid -  {valid:.5f}')\n",
    "    print(f'Average accuracy on crossval is {np.mean(valid_scores):.5f}')\n",
    "    print(f'Std is {np.std(valid_scores):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.62902   |   valid -  0.59259\n",
      "train -  0.64633   |   valid -  0.62963\n",
      "train -  0.63479   |   valid -  0.56296\n",
      "train -  0.65622   |   valid -  0.61481\n",
      "train -  0.63397   |   valid -  0.57778\n",
      "train -  0.64056   |   valid -  0.59259\n",
      "train -  0.64138   |   valid -  0.65926\n",
      "train -  0.65952   |   valid -  0.56296\n",
      "train -  0.64333   |   valid -  0.59701\n",
      "train -  0.63674   |   valid -  0.62687\n",
      "Average accuracy on crossval is 0.60165\n",
      "Std is 0.02943\n",
      "CPU times: user 1.59 s, sys: 72 ms, total: 1.66 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "               'penalty': ['l2', 'none']},\n",
    "              {'solver': ['saga'], 'penalty': ['l1', 'l2', 'none']},\n",
    "              {'solver': ['liblinear'], 'penalty': ['l1', 'l2']}]\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(fit_intercept=False, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'penalty': ['l2', 'none'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag']},\n",
       "                         {'penalty': ['l1', 'l2', 'none'], 'solver': ['saga']},\n",
       "                         {'penalty': ['l1', 'l2'], 'solver': ['liblinear']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'none', 'solver': 'sag'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313314057551975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='none', fit_intercept=False, random_state=21, solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(fit_intercept=False, penalty='none',\n",
       "                                          random_state=21, solver='sag'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': np.logspace(-4, 4, 20)}\n",
    "gs = GridSearchCV(lr, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313314057551975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', probability=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.70486   |   valid -  0.65926\n",
      "train -  0.69662   |   valid -  0.75556\n",
      "train -  0.69415   |   valid -  0.62222\n",
      "train -  0.70239   |   valid -  0.65185\n",
      "train -  0.69085   |   valid -  0.65185\n",
      "train -  0.68920   |   valid -  0.64444\n",
      "train -  0.69250   |   valid -  0.72593\n",
      "train -  0.70074   |   valid -  0.62222\n",
      "train -  0.69605   |   valid -  0.61940\n",
      "train -  0.71087   |   valid -  0.63433\n",
      "Average accuracy on crossval is 0.65871\n",
      "Std is 0.04359\n",
      "CPU times: user 9.94 s, sys: 80.7 ms, total: 10 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(svc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear', probability=True, random_state=21),\n",
       "             n_jobs=-1, param_grid={'C': [1, 10, 100]}, scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [1, 10, 100]}\n",
    "gs = GridSearchCV(svc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403662398457937"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.81039   |   valid -  0.74074\n",
      "train -  0.77741   |   valid -  0.74074\n",
      "train -  0.83347   |   valid -  0.70370\n",
      "train -  0.79720   |   valid -  0.76296\n",
      "train -  0.82440   |   valid -  0.75556\n",
      "train -  0.80379   |   valid -  0.68889\n",
      "train -  0.80709   |   valid -  0.76296\n",
      "train -  0.80132   |   valid -  0.65926\n",
      "train -  0.80807   |   valid -  0.75373\n",
      "train -  0.80478   |   valid -  0.68657\n",
      "Average accuracy on crossval is 0.72551\n",
      "Std is 0.03562\n",
      "CPU times: user 207 ms, sys: 4.39 ms, total: 211 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(dtc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(max_depth=10, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20]),\n",
       "                         'min_samples_split': [2, 3, 4]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'criterion': ['gini','entropy'],\n",
    "              'max_depth': np.arange(3, 21),\n",
    "              'min_samples_split': [2, 3, 4]}\n",
    "gs = GridSearchCV(dtc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679223461379595"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.96455   |   valid -  0.88148\n",
      "train -  0.96208   |   valid -  0.91852\n",
      "train -  0.96785   |   valid -  0.86667\n",
      "train -  0.96455   |   valid -  0.89630\n",
      "train -  0.96538   |   valid -  0.91111\n",
      "train -  0.96538   |   valid -  0.88148\n",
      "train -  0.97115   |   valid -  0.91852\n",
      "train -  0.96867   |   valid -  0.85185\n",
      "train -  0.97364   |   valid -  0.88060\n",
      "train -  0.97941   |   valid -  0.86567\n",
      "Average accuracy on crossval is 0.88722\n",
      "Std is 0.02204\n",
      "CPU times: user 2.6 s, sys: 49.5 ms, total: 2.65 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=14, n_estimators=50,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20]),\n",
       "                         'min_samples_split': [2, 3, 4]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'criterion': ['gini','entropy'],\n",
    "              'max_depth': np.arange(3, 21),\n",
    "              'min_samples_split': [2, 3, 4]}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8946413327825967"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260355029585798"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs.best_estimator_, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs.best_estimator_, 'model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
